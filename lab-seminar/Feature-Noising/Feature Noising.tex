\documentclass{article}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{thmtools}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{framed}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{kotex}
\usepackage{indentfirst}

\setlength{\parindent}{0.2in} % 들여쓰기 길이 설정
\setlength{\parskip}{1mm} % 문단 간의 간격 조절

\colorlet{LightGray}{White!90!Periwinkle}
\colorlet{LightOrange}{Orange!15}
\colorlet{LightGreen}{Green!15}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}

\declaretheoremstyle[name=Theorem,]{thmsty}
\declaretheorem[style=thmsty,numberwithin=section]{theorem}
\tcolorboxenvironment{theorem}{colback=LightGray}

\declaretheoremstyle[name=Proposition,]{prosty}
\declaretheorem[style=prosty,numberlike=theorem]{proposition}
\tcolorboxenvironment{proposition}{colback=LightOrange}

\declaretheoremstyle[name=Principle,]{prcpsty}
\declaretheorem[style=prcpsty,numberlike=theorem]{principle}
\tcolorboxenvironment{principle}{colback=LightGreen}

\setstretch{1.2}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}

% ------------------------------------------------------------------------------

\begin{document}

% ------------------------------------------------------------------------------
% Cover Page and ToC
% ------------------------------------------------------------------------------

\title{ \normalsize \textsc{}
		\\ [2.0cm]
		\HRule{1.5pt} \\
		\LARGE \textbf{\uppercase{Feature Noising \\ for Log-linear Structured       Prediction}
		\HRule{2.0pt} \\ [0.6cm] \LARGE{논문 리뷰} \vspace*{10\baselineskip}}
		}
\date{}

\maketitle
\newpage

\tableofcontents
\newpage

% ------------------------------------------------------------------------------
\section{요약}

NLP(Natural Language Processing) 모델은 많고 희소한 feature들을 갖고 있으며, 정규화(\textbf{regularization})는 모델의 과적합과 과소적합의 밸런스 유지에 중요합니다. 최근에 조명되는 정규화 방법 중 하나는 실제 데이터에 반복적으로 노이즈를 추가하여 fake training data를 생성하는 것입니다. 이러한 노이징을 정규화로 재해석하고, 가짜 데이터를 생성하지 않고도 훈련 중에 사용할 수 있는 \textbf{2차 공식으로 근사}하는 방법을 소개합니다. 이 방법은 \textbf{다항 로지스틱 회귀} 및 \textbf{CRF}(Conditional Random Field)를 사용한 구조화된 예측에 적용하는 방법을 설명합니다. 정규화 항을 효율적으로 계산하기 위한 \textbf{dynamic programming}이라는 핵심 과제를 다루며, 이 정규화 항은 입력 값의 합으로 이루어져 있으므로 \textbf{semi-supervised learning} 또는 \textbf{transductive extension}을 통해 더 정확하게 추정할 수 있습니다. 텍스트 분류, 개체명 인식(Named Entity Recognition)에 적용한 결과, 우리의 방법은 표준 L2 정규화 사용 대비 성능 향상이 \textbf{1\% 이상}을 제공합니다.
% ------------------------------------------------------------------------------
\section{소개}
NLP 모델은 수백만 이상의 희소한 feature들을 가지고 있습니다. 결과적으로, 가중치 정규화를 통한 과적합과 과소적합을 균형잡는 것은 최적의 성능을 달성하기 위한 핵심 이슈입니다. 전통적으로는 L2 또는 L1 정규화가 사용되지만, 이러한 심플한 유형은 실제 모델의 특성을 고려하지 않고 모든 feature들을 균일하게 페널티를 부과합니다.\\

정규화의 대안적 접근 방식은 원래 훈련 데이터의 input feature에 노이즈를 랜덤하게 추가하여 가짜 훈련 데이터를 생성하는 것입니다. \textit{직관적으로 이것은 맞춤법 오류 또는 이전에 본 적 없는 동의어를 사용할 때와 같이 누락된 feature들을 시뮬레이션하는 것으로 생각할 수 있습니다.} 이 기술의 효과는 기계 학습에서 잘 알려져 있지만, corrupt된 데이터셋 사본을 직접 다루는 것은 계산적으로 불가능할 수 있습니다. 다행히, feature noising 아이디어는 종종 직접 최적화할 수 있는 추적 가능한 결정적 목표로 이어집니다. 때로는 corrupt된 feature들로 훈련하는 것이 정규화의 특별한 형태로 축소되기도 합니다. 예를 들어, Bishop (1995)는 addtive gausian noise로 corrupt된 feature로 훈련하는 것이 낮은 노이즈로 제한한 L2 정규화의 형태와 동등하다는 것을 보였습니다. 다른 경우에는 인위적인 노이즈를 marginalizing하여 새로운 objective function을 개발하는 것이 가능합니다.\\

이 논문의 핵심 기여는 실제로 노이즈 데이터를 생성하지 않고도 log-linear structured prediction에서 인위적으로 노이즈된 feature들로 훈련을 효과적으로 시뮬레이션하는 방법을 보여주는 것입니다. 본문에서 feature noise로 최근 핫한 \textbf{dropout noise}(Hinton et al., 2012)에 집중합니다. 이것은 각 training 예제마다 독립적으로 feature의 무작위 부분 집합을 생략하는 방식으로 동작합니다. Dropout 및 그 변형은 다양한 작업에서 L2 정규화를 능가하는 것으로 입증되었습니다. Dropout은 feauture를 의도적으로 제거하는 feature bagging과 유사합니다. 그러나 다른점은 feature bagging은 무작위로 제거하는 대신 Dropout은 미리 설정된 방식으로 제거를 수행합니다.\\

우리의 접근 방식은 Bishop (1995) 및 Wager et al. (2013) 등에 의해 개발된 feature noising의 2차 근사에 기반하며, 이를 통해 dropout noise를 적응형 정규화의 형태로 변환할 수 있습니다. 이 방법은 2차 도함수를 계산할 수 있는 로그-선형 모델의 구조화된 예측에 적합합니다. 특히, 이는 최대 엔트로피 모델(소프트맥스 또는 다항 로지스틱 회귀라고도 함)을 사용한 \textbf{다중 클래스 분류} 및 NLP에서 일반적인 시퀀스 모델인 선형 체인 조건부 랜덤 필드(\textbf{CRFs})를 통해 사용할 수 있습니다.\\

linear-chain CRF의 경우, 우리는 \textbf{클리크 구조}를 활용하는 noising scheme을 어떻게 사용할 수 있는지 추가로 보여줍니다. 이를 통해 결과적인 노이징 정규화 항을 pairwise marginals로 계산할 수 있습니다. 그런 다음 단순한 전진-후진 형태의 dp를 사용하여 추적 가능한 gradient를 계산할 수 있습니다. 구현의 편의성과 semi-supervised로 확장성을 위해 더 빠른 정규화 근사도에 대한 개요도 제공합니다. 일반적인 접근 방식은 클리크 mariginals를 효율적으로 계산할 수 있는 경우에 선형 체인 이외의 다른 클리크 구조에서도 작동합니다.\\

마지막으로, 우리는 구조화된 예측을 위한 feature noising을 transductive 또는 semi-supervised 세팅으로 확장합니다. feature noising에 의해 유발된 정규화 항은 로그-선형 모델에서 레이블에 독립적이므로 레이블이 없는 데이터를 사용하여 더 나은 정규화를 학습할 수 있습니다. NLP 시퀀스 라벨링 작업은 특히 semi-supervised 접근에 적합하며, input feature이 많지만 희소하며, 레이블이 달린 데이터를 얻는 것이 비용이 많이 들지만 레이블이 없는 데이터는 풍부하기 때문입니다.\\

Wager et al. (2013)은 로지스틱 회귀에 대한 semi-supervised dropout training이 엔트로피 정규화(Grandvalet and Bengio, 2005) 및 변환 SVM(Joachims, 1999)과 같은 기법과 유사한 직관을 포착한다는 것을 보여주었고, 이는 레이블이 지정되지 않은 데이터에 대한 자신감 있는 예측을 장려합니다. 이러한 기법들은 라벨이 없는 데이터에서 확신 있는 예측을 장려하는 것입니다. semi-supervised dropout은 라벨이 없는 데이터에서 예측된 라벨 확률만 사용하여 L2 정규화를 조절하는 장점이 있으며, 엔트로피 정규화나 예상 정규화(Mann and McCallum, 2007)와 같이 보다 무겁게 처리하는 대신에 활용됩니다.\\

실험 결과에서 보여주는 바는, 시뮬레이션된 feature noising이 텍스트 분류 및 명명 Entity Recognition (NER) 순차 라벨링 작업에서 L2 정규화 대비 성능을 1\% 이상 절대적으로 향상시킨다는 것입니다.

\section{Feature noising Log-linear Models}
이 표현은 일반적인 구조화된 예측 문제를 설명하고 있으며, 주어진 입력 $x$ (예: 문장)을 출력 $y$ (예: 태그 시퀀스)로 매핑하는 문제를 다루고 있습니다. 여기서 $f(y, x) \in R^d$는 feature vector, $θ ∈ R^d$는 weighted vector, 그리고 $s = (s_1, . . . , s_|Y|)$는 각 출력에 대한 score vector입니다. 여기서 $sy = f(y, x) · θ$로 정의되며, 이것은 출력 $y$와 입력 $x$에 대한 feature vector $f(y, x)$와 weighted vector $θ$의 내적입니다. 이것은 로그-선형 모델을 정의하는 것입니다.

\begin{align}
    p(\textbf{y} \vert x ; \theta) = exp\{s_\textbf{y} - A(\textbf{s}) \},
\end{align}

여기서 $A(s)$는 로그-파티션 함수를 나타내며, $A(s) = log \sum_y exp\{s_\textbf{y}\}$와 같이 정의됩니다. 주어진 예제 $(x, \textbf{y})$에 대한 파라미터 추정은 $p(\textbf{y} | x; \theta)$를 최대화하기 위해 $\theta$를 선택하는 것을 의미합니다. 즉, 주어진 입력 x와 출력 y에 대해 가중치 벡터 θ를 선택하여 조건부 확률 $p(\textbf{y} | x; \theta)$를 최대화하는 것이 목표입니다.\\

Feature Noising의 핵심 아이디어는 특성 벡터 $f(\textbf{y}, x)$를 임의로 손상시켜 어떤 ˜f(y, x)로 만든 다음, 이러한 손상된 특성을 고려하여 y의 평균 로그-우도를 최대화하는 것입니다. 이러한 손상된 특성에 대응하는 ˜s, p˜(y | x; θ)라고 가정합니다. 또한 특성 노이징이 평균을 보존한다고 가정합니다: E[˜f(y, x)] = f(y, x), 따라서 E[˜s] = s입니다. 이것은 노이징 스키마 목록에 설명된대로 노이징된 특성을 조절하여 항상 수행할 수 있습니다.\\

feature noising을 정규화의 한 형태로 보는 것이 유용합니다. feature noising은 평균을 보존하기 때문에 feature noising 목적 함수는 원래의 로그-우도와 로그 정규화 상수의 차이로 나타낼 수 있습니다. 이것은 다음과 같이 표현할 수 있습니다:


\begin{align}
    E[\log \tilde{p}(y | x; \theta)] &= E[\tilde{s}y - A(\tilde{s})] \\
    &= \log p(y | x; \theta) - R(\theta, x) \\
    R(\theta, x) &\equiv E[A(\tilde{s})] - A(s)
\end{align}


$A(\cdot)$는 covex이기 때문에, $R(\theta, x)$ 은 젠슨부등식으로 인해 항상 positive하고 정규화항으로 해석할 수 있습니다. $R(\theta, x)$은 일반적으로 non-convex합니다.

정규화항 (4)을 계산하려면 모든 가능한 noise가 추가된 feature vector에 대한 합을 계산해야 하며, 이는 피처의 수에 exponential effort를 의미할 수 있습니다. 심지어 flat classification에 대해서도 이는 계산하기 불가능합니다. Bishop (1995) 및 Wager et al. (2013)을 따라 우리는 노이즈가 추가된 score vector ˜s의 로그-파티션 함수 $A(\cdot)$를 ˜s의 평균과 공분산만 사용하여 근사화하고 이를 통해 작업할 수 있도록 2차 근사값을 취합니다.

\begin{align}
    A(\tilde{s}) \approx A(s) + \nabla A(s)^T(\tilde{s} - s) + \frac{1}{2}(\tilde{s} - s)^T \nabla^2 A(s)(\tilde{s} - s).
\end{align}

(5)식을 (4)식에 넣으면,새 정규화 항 $R_q(\theta, x)$을 얻고, 이것을 $R(\theta, x)$의 근사치로 사용할 것입니다.:

\begin{align}
R_q(\theta, x) &= \frac{1}{2} E[(\tilde{s} - s)^T \nabla^2 A(s)(\tilde{s} - s)] \\
&= \frac{1}{2} \operatorname{tr}(\nabla^2 A(s) \operatorname{Cov}(\tilde{s}))
\end{align}

이 표현에는 여전히 두 가지의 잠재적인 비실용적인 요소가 있습니다. 지수적인 수의 노이즈가 추가된 점수 벡터 ˜s에 대한 합과 ˜s의 |Y| 개의 구성 요소에 대한 합이 있습니다.

다중 클래스 분류의 경우, ˜s의 구성 요소가 독립적이라고 가정한다면 Cov(˜s)는 R |Y|×|Y|의 diagonal matrix이며, 다음과 같이 표현할 수 있습니다.

\begin{align}
R_q(\theta, x) = \frac{1}{2} \sum_{y \in Y} \mu_y(1 - \mu_y) \text{Var}[\tilde{s}_y] \quad
\end{align}

평균은 $\mu_y \stackrel{\text{def}}{=} p_{\theta}(y \vert x)$는 모델 확률을 나타내며, 분산은 $\mu_y(1-\mu_y)$ 은 모델의 불확실성을 측정합니다. 그리고 (9) 식은,

\begin{align}
    Var[\tilde{s}_y] = \theta^T \text{Cov}[\tilde{f}(\textbf{y}, x)]\theta
\end{align}

feature noising으로부터 발생한 불확실성을 측정합니다. 정규화 항 $R^q(θ, x)$은 두 가지 분산 항의 곱으로 구성됩니다. 첫 번째 항은 θ에 대해 non-convex하며, 두 번째 항은 θ에 대해 quadratic합니다. 이 정규화를 최소화하는 것은 (i) 확신 있는 예측을 하는 모델과 (ii) 특징 노이즈에 노출되더라도 안정된 점수를 유지하는 모델을 선호함을 의미합니다.\\

다중 클래스 분류의 경우 정규화를 계산하기 위해 모든 y ∈ Y를 명시적으로 합산할 수 있지만 구조화된 예측에 대해서는 계산이 불가능할 것입니다. 여기서는 단기간 동안 다중 클래스 분류로 특화되도록 가정하겠습니다. 각 출력 y에 대해 동일한 특징 벡터 g(x)에 적용되는 별도의 가중치 벡터를 가지고 있다고 가정하면, 스코어 sy = θy·g(x)가 됩니다. 또한, 노이즈가 추가된 특징 벡터 g˜(x)의 구성 요소가 서로 독립적이라고 가정합니다. 그러면 (9)를 다음과 같이 단순화할 수 있습니다.:

\begin{align}
    \text{Var}[\tilde{s}_y] = \sum_j \text{Var}[g_j(x)]\theta_y_j^2.
\end{align}

노이즈 스키마는 원래 특성 f(y, x)을 사용하여 ˜f(y, x)를 생성하는 데 사용되는 방식의 예시입니다. 이 분포는 분산 항 Var[˜sy]을 통해 정규화에 영향을 미칩니다.

\begin{itemize}
    \item \textbf{Additive Gaussian}:
    $\tilde{f}(y, x) = f(y, x) + \epsilon, \quad \text{where} \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I_{d \times d}).$\\
    이 경우, noising에 의한 정규화 항의 기여는 다음과 같이 표현됩니다.\\
    \begin{align*}
        Var[\tilde{s}_y] = \sum_j \sigma^2 \theta^2_{yj}\\
    \end{align*}
    
    \item \textbf{Dropout}:
    $f(y, x) = f(y, x) ☉ z$의 경우, 여기서 $☉$는 두 벡터의 원소별 곱을 취하는 연산을 나타냅니다. 여기서 z는 독립적인 성분을 가진 벡터이며, zi는 확률 δ로 0이고, 확률 1 - δ로 1/ (1 - δ)입니다. 이 경우, Var[˜sy]는 다음과 같이 표현됩니다:\\
    \begin{align*}
        Var[\tilde{s}_y] = \sum_j (g_j(x))^2 \frac{\delta}{1 - \delta} \theta_{yj}^2
    \end{align*}

    \item Multiplicative Gaussian:
    $f(y, x) = f(y, x) \odot (1 + \epsilon), \text{ where } \epsilon \sim \mathcal{N}(0, \sigma^2 I_{d \times d})$. 분산항은 $\sum_j g_j(x)^2 \sigma^2 \theta_y^2$로 표현됩니다.\\ 
    참고로, 두 번째 2nd-order approx인 Rq(θ, x)에서는 mulit~ gausian과 dropout scheme가 동일하지만, 원래 정규화항 R(θ, x)에서는 차이가 있습니다.
\end{itemize}

\subsection{준지도학습}
중요한 관찰(Wager et al., 2013) 중 하나는, noising regularizer R(8)가 예제를 대상으로 한 합계를 포함하더라도 출력 y와 독립적이라는 것입니다. 이는 미분되지 않은 데이터를 사용하여 R을 추정하는 것을 제안합니다. 구체적으로, 레이블이 지정된 n개의 예제 $D = \{x_1, x_2, . . . , x_n\}$와 레이블이 지정되지 않은 m개의 예제 $Dunlabeled = \{u_1, u_2, . . . , u_n\}$이 있다면, 두 데이터셋에서 추정된 regularizer의 선형 조합으로 정의된 regularizer를 정의할 수 있으며, $α$는 두 데이터셋 간의 균형을 조절합니다.

\begin{align}
    R_*(\theta, D, Dunlabeled) = \frac{n}{n + \alpha m} \left( \sum_{i=1}^n R(\theta, x_i) + \alpha \sum_{i=1}^m R(\theta, u_i) \right).
\end{align}

\section{Feature Noising in Linear-Chain CRFs}
지금까지 우리는 모든 log linear model에 적용할 수 있는 regularizer를 개발했지만, 현재의 형태로는 다중 클래스 분류에만 실용적입니다. 이제 CRF에서 분해 가능한 구조를 활용하여 모든 가능한 출력 y ∈ Y를 명시적으로 합산할 필요가 없는 새로운 noising method를 정의하겠습니다. 핵심 아이디어는 각각의 y를 독립적으로 노이즈 처리하는 대신 각 local feature vector를 노이즈 처리하는 것(이것이 많은 y에 암묵적으로 영향을 미침)입니다.\\

output $y = (y_1, . . . , y_T )$가 태그 T의 seq인 것으로 가정합니다. 선형 체인 CRF에서 feature vector f는 local feature veoctor $g_t$의 합으로 분해됩니다.

\begin{align}
    f(y, x) = \sum_{t=1}^T g_t(y_{t-1}, y_t, x)
\end{align}
$g_t(a, b, x)$는 t-1 위치와 t 위치에 대한 연속된 태그 쌍 a와 b에 대해 정의된 함수입니다.\\
우리는 각각의 태그 쌍 $(a, b)$와 위치 $t = 1, . . . , T$에 대한 local score set $s = {sa,b,t}$를 정의하는 대신, 각각의 $a, b, t$에 대해 $\tilde{g}_t(a, b, x)$를 독립적으로 설정하는 노이징 방법을 고려합니다. 이에 해당하는 노이즈가 추가된 스코어 집합을 $\tilde{s} = {\tilde{s}_a_b_t}$로 정의합니다.\\
우리는 local score들의 log partition fuction을 다음과 같이 쓸 수 있습니다.
\begin{align}
    A(s) = \log \sum_{y \in Y} \exp \left( \sum_{t=1}^{T} s_{y_{t-1},y_{t},t} \right)
\end{align}

첫 번째 도함수는 모델에 따른 edge margin을 나타내며, 즉, $µ_a_b_t = p_θ(yt−1 = a, yt = b \vert x)$ 입니다. 또한 hessain matrix의 대각 성분은 margianl variances를 나타냅니다.\\
식 (7), (8)에 의해 정규화항을 다음과 같이 얻습니다:
\begin{align}
    R_q(\theta, x) = \frac{1}{2} \sum_{a,b,t} \mu_{a,b,t} (1 - \mu_{a,b,t}) \text{Var}[\tilde{s}_{a,b,t}]
\end{align}

여기서 $\mu_{a,b,t}(1 - \mu_{a,b,t})$는 edge margin에 대한 모델의 불확실성을 측정하며, $\text{Var}[\tilde{s}_{a,b,t}]$은 noise로 인한 불확실성을 나타냅니다. 다시 말해, 정규화를 최소화하는 것은 확신 있는 예측을 만들고 특성 노이즈에 대해 안정된 점수를 가짐을 의미합니다.

\paragraph{편미분 계산}
지금까지 우리는 feature noising를 기반으로 한 정규화 항인 $R^q(\theta, x)$를 정의했습니다. $R^q(\theta, x)$를 최소화하려면 그 도함수를 구해야 합니다. 먼저, $log µ_a_b_t$는 제한된 로그 파티션 함수와 로그 파티션 함수의 차이입니다. 따라서 다시 한 번 1차 도함수의 성질을 이용하면 다음과 같습니다:
\begin{align}
    \nabla \log \mu_{a,b,t} = \mathbb{E}_{p_\theta(y|x,y_{t-1}=a,y_t=b)}[f(y, x)] - \mathbb{E}_{p_\theta(y|x)}[f(y, x)]
\end{align}

$\nabla \mu_{a,b,t} = \mu_{a,b,t} \nabla log \mu_{a,b,t}$ 식과 $Var[\tilde{s}_{a,b,t}$가 θ에 대한 2차 함수임을 고려하여, 우리는 단순히 곱셈 법칙을 적용하여 최종 그레디언트 $\nabla R^q(\theta, x)$를 유도할 수 있습니다.

\end{itemize}

\subsection{조건부기대값의 동적 계획법}
$\nabla R^q(\theta, x)$를 계산하기 위한 나이브한 방법은 모든 태그 쌍 $(a, b)$와 위치 t에 대해 $E_{p_{\theta}(y|y_{t-1}=a, y_t=b, x)}[f(y, x)]$를 계산하기 위해 전방-후방 패스를 전부 수행해야 하며, 이로 인해 $O(K^4T^2)$ 시간 복잡도가 발생한다는 것을 의미합니다.\\

이 섹션에서, 복잡한 dp를 활용하여 시간복잡도를 $O(K^2T)$로 줄입니다.\\

CRFs의 마코프 성질을 이용하여 $y_{1:t−2}$는 $(y_{t1}, y_t)$를 통해 $y_{t−1}$에만 의존을 받고, $y_{t+1:T}$는 $(y_{t−1}, y_t)$를 통해 $y_t$에만 의존하도록합니다.\\

먼저, 위치 i에서 j까지의 local feature vector의 부분 합을 다음과 같이 정의하는 것이 편리할 것입니다.

\begin{align}
  G_{i:j} = \sum_{t=i}^{j} g_t(y_{t-1}, y_{t}, x)
\end{align}

$(a, b, t)$가 주어진 경우 feature의 기대값 $E_{p_\theta(y|y_{t-1}=a, y_t=b, x)}[f(y, x)]$을 계산하는 작업을 고려해 보겠습니다. 이 작업을 다음과 같이 확장할 수 있습니다.

\begin{align*}
    \sum_{\textbf{y}: y_{t-1}=a, y_t=b} p_\theta(y-(t-1:t) | y_{t-1} = a, y_t = b) G_{1:T}
\end{align*}

$y_{t-1}, y_t$에 대한 조건부로 나누면 합을 세 부분으로 나눌 수 있습니다.

\begin{align}
    F_a^t &= \sum_{y1:t-2} p_\theta(y1:t-2 | y_{t-1} = a) G1:t-1, \\
    B_b^t &= \sum_{y_{t+1:T}} p_\theta(y_{t+1:T} | y_t = b) G_{t+1:T},
\end{align}

\textit{$F_a^t$와 $B_b^t$는 각각 태그 시퀀스의 접두사(prefix)와 접미사(suffix) 위에서 feature vector들이 합산된 기대값}입니다. $F_a^t$와 $B_b^t$는 일반적인 CRF 추론의 forward와 backward 메시지와 유사하지만 스칼라가 아닌 벡터입니다.\\

이러한 메시지들은 표준 방식에서 재귀적으로 계산할 수 있습니다. Forward recurrence는 다음과 같습니다.

\begin{align*}
    F_a^t = \sum_b p_\theta(y_{t-2} = b | y_{t-1} = a)\\
    \left[ g_t(y_{t-2} = b, y_{t-1} = a, x) + F_b^{t-1} \right],
\end{align*}

backward message $B_b$도 비슷한 재귀적 관계를 가집니다.

위의 동적 계획법을 실행하는 데 걸리는 시간은 $O(K^2Tq)$이며, 저장 공간은 $O(KTq)$가 필요합니다. 여기서 K는 태그의 수, T는 시퀀스의 길이이며, q는 active features 수입니다. 이는 일반적인 CRF 훈련과 동일한 종속성 순서를 가지고 있지만 active features 수 q에 대한 추가적인 종속성이 있어 훈련이 더 느려집니다.

\section{빠른 그래디언트 계산들}
이 섹션에서는 먼거리 상호작용을 무시하거나 피처의 희소성을 활용하여 gradient 계산의 효율성을 더 개선하는 두 가지 방법을 제공합니다.

\subsection{feature의 희소성과 동시발생의 활용}
각각의 훈련 예제를 통한 각각의 순방향-역방향 패스에서, 해당 예제에서 활성화된 모든 feature의 조건부 기대값을 계산해야 합니다. 이전 섹션의 동적 계획법을 단순히 적용하면 각 active feature당 $O(K^2T)$의 복잡도가 발생합니다. 전체 복잡성은 active feature의 수인 q를 고려해야 합니다. q는 문장 길이와 선형적으로 스케일링되지만 실제로는 빠르게 증가할 수 있습니다. 예를 들어, NER 태깅 실험에서 (후반부 섹션 참조), 각 토큰당 평균 active feature 수는 약 20개이며 이는 $q \approx 20T$를 의미하므로 이 항목이 계산 비용을 빠르게 지배하게 됩니다. 다행히도 시퀀스 태깅 및 기타 NLP 작업에서는 대부분의 피처가 희소하며 종종 동시에 발생합니다. 즉, 일부 active feature는 주어진 시퀀스에서 동일한 위치에서만 발생하게 됩니다. 이는 특정 토큰이 여러 rare feature들을 활성화할 때 발생합니다.\\

우리는 위치 t에서 한 번만 발화한 모든 feature들이 같은 조건부 기대값 (및 모델 기대값)을 가지는 것을 관찰했습니다. 결과적으로 이러한 feature들의 그룹을 하나의 특징으로 축소하여 계산하는 동일한 기대값을 피하기 위한 전처리 단계로 사용할 수 있습니다. 이와 같이 NER 태깅 실험에서 q/T를 20에서 5 미만으로 줄이는 결과를 얻으며 정확도를 손실 없이 4배 빠르게 실행할 수 있습니다. 정확히 동일한 기교가 일반 CRF 기울기 계산에도 적용 가능하며 유사한 속도 향상을 제공합니다.

\subsection{단거리 상호작용}
또한, 근사 그래디언트를 사용하여 이 방법을 가속화하는 것이 가능합니다. 우리의 경우, 섹션 3의 동적 프로그램과 위에서 설명한 방법론을 함께 사용하면 관리 가능한 시간 내에 실행됩니다. 그러나 여기서 개발된 기술은 더 큰 작업에 유용할 수 있습니다.\\
다음과 같이 계산하려는 양을 약간 다르게 다시 작성해 봅시다 (다시 말해, 모든 a, b, t에 대해).

\begin{align}
    \sum_{i=1}^{T} \mathbb{E}_{p_{\theta}(y|x, y_{t-1}=a, y_t=b)} [g_i(y_{i-1}, y_i, x)]
\end{align}
이것은 $y_{t−1}$,$y_t$에 조건을 건 상태에서, i가 t에서 멀리 떨어진 경우 $g_i(y_{i−1}, y_i, x)$ 항목들은 $E_{pθ(y|x)}[gi(y_{i−1}, y_i, x)]$에 가깝게 될 것이라는 직관입니다.\\

이것은 어떤 창 크기 r을 사용하여 $\vert i − k \vert \geq r$ 일 때 이전 항목을 후자로 대체하도록 동기부여합니다. 이 근사치는 $i−r$에서 $i+r$까지의 local feature vector 합만 고려해야 하는 표현을 결과로 낳게 되며, 이는 $G_{i−r:i+r}$로 나타낼 수 있습니다.

\begin{align}
    &Ep_\theta(y|y_{t-1}=a,y_t=b,x)[f(y, x)] - Ep_\theta(y|x)[f(y, x)] \nonumber \\
    &\approx Ep_\theta(y|y_{t-1}=a,y_t=b,x)[G_{t-r:t+r}] - Ep_\theta(y|x)[G_{t-r:t+r}].
\end{align}

우리는 이 마지막 표현을 더 근사화하여 r = 0으로 설정하여 다음과 같이 얻을 수 있습니다:
\begin{align}
    g_{t}(a, b, x) - \mathbb{E}_{p_\theta(y|x)}[g_{t}(y_{t-1}, y_t, x)]
\end{align}
두 번째 기대값은 edge margin에서 계산할 수 있습니다.\\

이 근사치의 정확도는 장거리 종속성의 부재에 달려 있습니다. 식 (21)은 r = 0의 경우를 보여줍니다. 이것은 거의 추가 노력이 필요하지 않습니다. 그러나 일부 실험에서는 실제 미분과 20\% 차이가 있는 것을 관찰했습니다. $r > 0$인 경우, 계산 절약은 더 제한적이지만 윈도우 크기가 제한된 방법이 구현하기 더 쉽습니다.

\section{실험}
우리는 CoNLL-2003 Named Entity Recognition (NER) 작업, SANCL Part-of-speech (POS) 태깅 작업 및 여러 문서 분류 작업에 대한 실험 결과를 제시합니다. 사용된 데이터 세트는 Table 1에 설명되어 있습니다. 가능한 경우 표준 분할을 사용했으며, 그렇지 않은 경우 데이터를 무작위로 테스트 세트와 훈련 세트로 동일한 크기로 분할했습니다 (RCV14, TDT2). CoNLL은 51578 크기의 개발 세트를 가지고 있으며, 우리는 정규화 매개변수를 조정하기 위해 이를 사용했습니다. SANCL 테스트 세트는 답변, 뉴스 그룹 및 리뷰와 같은 3 가지 장르로 나뉘며 각각에 해당하는 개발 세트가 있습니다.

\subsubsection{다중클래스 분류}
우리는 $Y = {1, 2, . . . , K}$로 표시되는 K개 클래스에 대한 간단한 분류 작업에서 우리의 regularize를 테스트하기 시작합니다. 우리는 전체 지도 학습 환경과 transductive learning 환경에서 noising regularizer의 성능을 조사합니다.\\

transductive learning 환경에서는 학습자가 레이블 없이도 훈련 시간에 테스트 피처를 검사할 수 있습니다. 우리는 transductive dropout을 위해 섹션 2.1에서 설명한 방법을 사용했습니다.

\subsubsection{준지도에서 feature noising}
추론 학습 환경에서는 테스트 데이터(레이블 없음)를 사용하여 더 나은 regularizer를 학습하는데, 대안으로 테스트 데이터 대신 레이블이 없는 데이터를 사용하여 비슷한 목표를 달성할 수 있으며, 이는 준지도 학습 환경으로 이어집니다. 준지도 아이디어를 테스트하기 위해 위에서 설명한 데이터셋을 사용했습니다. 각 데이터셋을 훈련 세트, 테스트 세트 및 레이블이 없는 데이터셋으로 고르게 나누었습니다. 결과는 표 3에 제시되어 있습니다. 대부분의 경우, 준지도 학습 정확도가 표 2에 나와 있는 추론 학습 정확도보다 낮습니다. 이는 우리의 설정에서 준지도 분류기를 훈련하는 데 더 적은 레이블 데이터를 사용했기 때문에 정상입니다.

\subsubsection{2차 근사}
위에 보고된 결과는 모두 두 클래스 분류 작업에 기반한 두 번째 차원 테일러 전개에 기반한 근사적인 dropout regularizer(8)를 사용합니다. 이 근사법의 유효성을 검증하기 위해 Wang 및 Manning (2013)이 개발한 가우시안 방법과 비교합니다. 우리는 20-newsgroups의 alt.atheism 대 soc.religion.christian 분류 작업을 사용합니다. 결과는 그림 2에 표시되어 있으며, 22178개의 피처를 가진 1427개의 예제가 균등하게 훈련 세트와 테스트 세트로 무작위로 분할되었습니다.\\

넓은 범위의 λ 값에 대해 드롭아웃 플러스 L2 정규화가 어떤 λ 값에 대해서도 L2 정규화만 사용하는 것보다 훨씬 더 잘 수행됨을 발견했습니다. 가우시안 드롭아웃이 이 논문에서 논의된 이차 근사보다 약간 더 잘 수행되는 것으로 보입니다. 그러나 우리의 이차 근사는 다중 클래스 케이스와 일반적인 구조화 예측으로 쉽게 확장되며, 가우시안 드롭아웃은 그렇지 않습니다. 따라서 우리의 근사법은 계산 효율과 예측 정확도 사이의 합리적인 트레이드 오프를 제공하는 것으로 보입니다.

\subsection{CRF 실험}
우리는 이차 드롭아웃 정규화자를 선형 체인 CRF에서 두 개의 시퀀스 태깅 작업에 대해 평가합니다. CoNLL 2003 NER 공유 작업 (Tjong Kim Sang 및 De Meulder, 2003)과 SANCL 2012 POS 태깅 작업 (Petrov 및 McDonald, 2012)입니다.\\

표준 CoNLL-2003 영어 공유 작업 벤치마크 데이터 세트 (Tjong Kim Sang 및 De Meulder, 2003)는 Reuters 뉴스 와이어 기사의 문서 모음으로, Person, Location, Organization 및 Miscellaneous의 네 가지 엔터티 유형에 주석이 달려 있습니다. 우리는 BIO 태그를 고려하지 않고 레이블 시퀀스 Y = {LOC, MISC, ORG, PER, O}를 예측했습니다.\\

CRF 모델을 훈련하기 위해 Finkel et al. (2005)의 포괄적인 기능 집합을 사용했으며, 이 기능 집합은 이 작업에 대한 최첨단 결과를 제공합니다. CoNLL-2003 훈련 데이터 세트에서 총 437,906개의 기능이 생성되었습니다. 가장 중요한 기능은 다음과 같습니다:

\begin{itemize}
    \item 현재 위치에서의 단어, 단어 형태 및 문자 n-gram (최대 6-gram)
    \item 이전 및 다음 위치에서의 예측, 단어 및 단어 형태
    \item 현재 단어 형태와 함께 이전 단어 형태
    \item 이전 및 다음 4개 위치의 이질적인 단어 세트
    \item 3개 단어 창 내 대문자 패턴
    \item 이전 두 단어와 이전 단어의 단어 형태를 고려
    \item 현재 단어가 이름 제목 목록 (예: Mr., Mrs.)과 일치 여부
\end{itemize}
Fβ=1 결과는 표 4에 요약되어 있습니다. 테스트 세트와 개발 세트에서 각각 1.6\%와 1.1\%의 절대적인 성능 향상을 얻었습니다. 각 태그에 대한 정밀도와 재현율으로 세분화된 결과는 표 6에 표시되어 있습니다. 이러한 개선 사항은 2000번의 부트스트랩 재표본 추출 방법 (Efron 및 Tibshirani, 1993)을 기준으로 0.1\% 수준에서 유의미합니다.

SANCL (Petrov and McDonald, 2012) POS 태깅 작업에 대해서는 매우 간단한 기능 세트를 사용한 동일한 CRF 프레임워크를 사용했습니다.
\begin{itemize}
    \item 단어 유니그램: w−1, w0, w1
    \item 단어 바이그램: (w−1, w0) 및 (w0, w1)
\end{itemize}
우리는 (14)의 이차 드롭아웃 정규화를 사용하여 L2 정규화된 CRF 기준과 비교하여 작은 차이가 있었습니다.\\
SANCL에서의 차이는 작지만 리뷰 및 뉴스 그룹의 테스트 세트에서의 성능 차이는 0.1\% 수준에서 통계적으로 유의미합니다. 이것은 기능이 극히 희소한 상황이고 L2 정규화가 개선을 제공하지 않았으며 전반적으로 정규화가 중요하지 않은 상황에서 흥미로운 점입니다.

\section{결론}
저희는 다중 클래스 로지스틱 회귀 및 조건부 랜덤 필드와 같은 로그 선형 모델을 학습하기 위한 새로운 정규화 항을 제안했습니다. 이 정규화 항은 특성 노이징 스키마의 이차 근사에 기반하며, 데이터의 노이즈에 강하게 예측하고 안정적인 모델을 선호하려고 합니다. CRF에 우리 방법을 적용하기 위해, 우리는 구조적 예측 설정에서 발생하는 특성 상관 관계를 다양한 방식으로 다루는 중요한 도전 과제를 해결했습니다. 또한, 우리는 이 정규화 항을 자연스럽게 준지도 학습 환경에 적용할 수 있음을 보였습니다. 마지막으로, 우리는 이 방법을 다양한 데이터셋에 적용하여 표준 L2 정규화에 비해 일관된 이득을 입증했습니다. 이 비볼록 정규화 항을 온라인으로 더 잘 최적화하고 준지도 학습 환경으로 효과적으로 확장하는 것은 흥미로운 미래 연구 방향으로 보입니다.


\end{document}
